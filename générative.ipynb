{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wnnaXNPCYGLS"
   },
   "source": [
    "--- \n",
    "--- \n",
    "# Partie générative\n",
    "--- \n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tm6yZwSkjyou"
   },
   "source": [
    "Ce notebook contient notre modèle pour générer un texte original dans le cas où la question de l'utilisateur n'est pas orientée tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xOUomBGQYNrR"
   },
   "source": [
    "---\n",
    "## Importation des bibliothèques et modules\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfQVFJNxgO6M"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KezlozQrq_1F"
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20699,
     "status": "ok",
     "timestamp": 1580657057077,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "E3gxIY8Phr7i",
    "outputId": "533728cc-35a5-4f07-fda9-41aa0a618be1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwHcOCmGi1tr"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/gdrive/My Drive/OpenSubtitles.de-fr.fr\" , encoding='utf-8') as f :\n",
    "    subtitles = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_diHW_Wk-mS"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "## Approche par caractères\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dILTN5NJhu1Q"
   },
   "source": [
    "Avant d'entrainer le modèle, nous avons converti les chaines de caractères en numérique. Nous avons pour cela crée deux tables. L'une converti les caractères en nombres et la deuxième fait le processus inverse. Chaque caractère présent dans la base de texte OPUS a maintenant un nombre qui lui est attribué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8YWyLNf69z_"
   },
   "outputs": [],
   "source": [
    "subtitles = subtitles[0:int(len(subtitles)/10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwGV-b-e7Az9"
   },
   "source": [
    "Nous avons appris sur seulement 20% de la base pour réduire le temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_6IOtZT4lQZV"
   },
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "vocab = sorted(set(subtitles))\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "text_as_int = np.array([char2idx[c] for c in subtitles])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNPV0eSAkeUY"
   },
   "source": [
    "Nous enregistrons ces deux tables car nous en aurons besoin dans la partie principale qui rassemble les éléments du chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gnn8t0gFFqq0"
   },
   "outputs": [],
   "source": [
    "pickle.dump(char2idx, open('/content/gdrive/My Drive/lst_char.pkl','wb'))\n",
    "pickle.dump(idx2char, open('/content/gdrive/My Drive/lst_idx.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmekgCvCm9Y5"
   },
   "source": [
    "---\n",
    "# La prédiction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGhFxIpclRFq"
   },
   "source": [
    "Maintenant en entrant une séquence de caractères (dans notre cas la question de l'utilisateur), nous devons déterminer quels caractères sont les plus probables pour dialoguer avec l'utilisateur. Nous allons pour cela utiliser un modèle RNN. Nous choisissons de faire un modèle qui retourne au maximum 100 caractères à l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q7ALIhFGpCIP"
   },
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = (len(subtitles)/10)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NaSZfS8o_nT"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywdNjuMLo-HJ"
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1580657095007,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "ddtjpVWVv8uh",
    "outputId": "ac76b5b7-3173-424b-f40c-712108471430"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GyIfip89wBR5"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1mdz_nqMwFrx"
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lPYI4CCswKvG"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8191,
     "status": "ok",
     "timestamp": 1580657110077,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "SwnIQ69FwOnf",
    "outputId": "5a96e50d-3b4b-4a41-cac9-498520cd5f09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 223) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1580657110752,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "F3opiVSOwWcm",
    "outputId": "540d9f48-ce2d-45ad-b1ea-820912d2bc06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           57088     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 223)           228575    \n",
      "=================================================================\n",
      "Total params: 4,223,967\n",
      "Trainable params: 4,223,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCS_JXrkwY7t"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1580657111591,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "hw272vkGwr8Y",
    "outputId": "1e0bcd30-ddca-46cf-8ec5-2a86331a7c6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 223)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       5.4073415\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_2njnbwHwwET"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSSb3G7ew-XX"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qUQ_ILnQwzyO"
   },
   "outputs": [],
   "source": [
    "EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5263657,
     "status": "ok",
     "timestamp": 1580662384410,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "hSaVAHfEw7ml",
    "outputId": "ee419948-8fc0-47c1-898c-6883d1b525b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 8642 steps\n",
      "Epoch 1/10\n",
      "8642/8642 [==============================] - 519s 60ms/step - loss: 1.2964\n",
      "Epoch 2/10\n",
      "8642/8642 [==============================] - 527s 61ms/step - loss: 1.1694\n",
      "Epoch 3/10\n",
      "8642/8642 [==============================] - 527s 61ms/step - loss: 1.1637\n",
      "Epoch 4/10\n",
      "8642/8642 [==============================] - 528s 61ms/step - loss: 1.1785\n",
      "Epoch 5/10\n",
      "8642/8642 [==============================] - 527s 61ms/step - loss: 1.4678\n",
      "Epoch 6/10\n",
      "8642/8642 [==============================] - 527s 61ms/step - loss: 1.9389\n",
      "Epoch 7/10\n",
      "8642/8642 [==============================] - 527s 61ms/step - loss: 1.9376\n",
      "Epoch 8/10\n",
      "8642/8642 [==============================] - 528s 61ms/step - loss: 1.6646\n",
      "Epoch 9/10\n",
      "8642/8642 [==============================] - 527s 61ms/step - loss: 1.3502\n",
      "Epoch 10/10\n",
      "8642/8642 [==============================] - 525s 61ms/step - loss: 1.2752\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1580662385401,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "46L2aM_6ymh9",
    "outputId": "3252ff25-150d-4fad-be68-a0098edc7912"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt_10'"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tz4FMUoZyqPI"
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1580662385811,
     "user": {
      "displayName": "sarah faucon",
      "photoUrl": "",
      "userId": "00071383878885981401"
     },
     "user_tz": -60
    },
    "id": "xd1xZszgytoC",
    "outputId": "08c4f037-ed88-49be-9a6d-fa656a1531c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            57088     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 223)            228575    \n",
      "=================================================================\n",
      "Total params: 4,223,967\n",
      "Trainable params: 4,223,967\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtvXRqrk48Mv"
   },
   "outputs": [],
   "source": [
    "model.save('/content/gdrive/My Drive/generative_model.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM3JEBUCqy2AkhNZB4J3Wfh",
   "collapsed_sections": [],
   "name": "générative.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
